# Copyright (c) 2020 Idiap Research Institute, http://www.idiap.ch/
#  Written by Srikanth Madikeri <srikanth.madikeri@idiap.ch>

import torch
from _pkwrap import kaldi
from torch.nn.utils import clip_grad_value_
import sys
import random
from collections import OrderedDict

class KaldiChainObjfFunction(torch.autograd.Function):
    """LF-MMI objective function for pytorch

    This Function wraps MMI loss function implemented in Kaldi.
    See Pytorch documentation of how to extend Function to check
    the attributes present. I expect that this class will be used
    as follows

    ```
        lfmmi_loss = KaldiChainObjfFunction.apply
        ...
        lfmmi_loss(chain_opts, den_graph, egs, nnet_output, xent_output)
    ```
    """
    @staticmethod
    def forward(ctx, opts, den_graph, supervision, nnet_output_tensor,
                xent_out_tensor):
        """This function computes the loss for a single minibatch. 

        This function calls Kaldi's ComputeChainObjfAndDeriv through our
        pybind11 wrapper. It takes the network outputs, rearranges them
        in the way Kaldi expects, gets back the derivates of the outputs.
        We pre-allocate the space for derivatives before passing to Kaldi.
        No extra space is used by Kaldi as we pass only the poitners.

        Args:
            opts: training options for the loss function
            den_graph: Denominator graph 
            supervision: merged egs for the current minibatch
            nnet_output_tensor: output generated by the network
            xent_out_tensor: the corresponding cross-entropy output
        
        Returns:
            We normally don't use the output returned by the function.
            The derivatives are stored in the context and used by the backward()
            function.
        """
        objf = torch.zeros(1)
        l2_term = torch.zeros(1)
        weight = torch.zeros(1)
        mb, T, D= nnet_output_tensor.shape
        # Kaldi expects the outputs to be groups by time frames. So
        # we need to permut the output
        nnet_output_copy = nnet_output_tensor.permute(1, 0, 2).reshape(-1, D).contiguous()
        nnet_deriv = torch.zeros_like(nnet_output_copy)
        xent_deriv = torch.zeros_like(nnet_output_copy)
        kaldi.chain.ComputeChainObjfAndDeriv(opts, den_graph, supervision, nnet_output_copy, 
                objf, l2_term, weight,
                nnet_deriv, xent_deriv)
        # return the derivates in the original order
        nnet_deriv = nnet_deriv.reshape(T, mb, D).permute(1, 0, 2)
        xent_deriv = xent_deriv.reshape(T, mb, D).permute(1, 0, 2)        

        ctx.save_for_backward(nnet_deriv, xent_deriv)
        xent_objf = (xent_out_tensor*xent_deriv).sum()/(mb*T)
        objf[0] = objf[0]/weight[0]
        sys.stderr.write("objf={}, l2={}, xent_objf={}\n".format(objf[0], l2_term[0]/weight[0], xent_objf))
        return objf
    @staticmethod
    def backward(ctx, dummy):
        """returns the derivatives"""
        nnet_deriv, xent_deriv = ctx.saved_tensors
        return None, None, None, -nnet_deriv, -0.1*xent_deriv


class OnlineNaturalGradient(torch.autograd.Function):
    """A wrapper to NG-SGD class in Kaldi

    This class wraps Natural Gradient implemented in Kaldi by calling
    nnet3's precondition_directions (wrapped through pybind11)
    When implemented as an autograd Function we can easily wrap
    it in a Linear layer. See pkwrap.nn.NaturalAffineTransform.
    """
    @staticmethod
    def forward(ctx, input, weight, bias, in_state, out_state):
        """Forward pass for NG-SGD layer
        
        Args:
            input: the input to the layer (a Tensor)
            weight: weight matrix of the layer (a Tensor)
            bias: the bias parameters of the layer (a Tensor)
            in_state: state of the input (a kaldi.nnet3.OnlineNaturalGradient object)
            out_state: state of the output (a kaldi.nnet3.OnlineNaturalGradient object)
        
        Returns:
            Linear transformation of the input with weight and bias.
            The other inputs are saved in the context to be used during the call
            to backward.
        """
        ctx.save_for_backward(input, weight, bias)
        ctx.states = [in_state, out_state]
        # the code below is based on pytorch's F.linear
        if input.dim() == 2 and bias is not None:
            output = torch.addmm(bias, input, weight.t())
        else:
            output = input.matmul(weight.t())
            if bias is not None:
                output += bias
        return output

    @staticmethod
    def backward(ctx, grad_output):
        """Backward pass for NG-SGD layer

        We pass the gradients computed by Pytorch to Kaldi's precondition_directions
        given the states of the layer.
        """
        input, weight, _ = ctx.saved_tensors
        in_state, out_state = ctx.states
        if input.dim() == 3:
            mb, T, D = input.shape
            mb_T = mb*T
        else:
            mb_T, D = input.shape
        input_temp = torch.zeros(mb_T, D+1, device=input.device).contiguous()
        input_temp[:,-1] = 1.0
        input_temp[:,:-1].copy_(input.reshape(mb_T, D))
        grad_weight = grad_bias = None
        if grad_output.dim() == 3:
            grad_input = grad_output.matmul(weight)
            grad_input = grad_input.reshape(mb, T, D)
        else:
            grad_input = grad_output.mm(weight)
        in_scale = kaldi.nnet3.precondition_directions(in_state, input_temp)
        out_dim = grad_output.shape[-1]
        grad_output_temp = grad_output.view(-1, out_dim)
        out_scale = kaldi.nnet3.precondition_directions(out_state, grad_output_temp) # hope grad_output is continguous!
        scale = in_scale*out_scale
        grad_output.data.mul_(scale)
        # TODO: check if we should use data member instead?
        grad_weight = grad_output_temp.t().mm(input_temp[:,:-1])
        grad_bias = grad_output_temp.t().mm(input_temp[:,-1].reshape(-1,1))
        grad_weight.data.mul_(scale)
        grad_bias.data.mul_(scale)
        return grad_input, grad_weight, grad_bias.t(), None, None


# take a scp file
class ChainExample(torch.utils.data.Dataset):
    """A Dataset wrapper to egs objects in Kaldi

    This is a generic wrapper to handling egs files generated by Kaldi.
    With this class we can iterate over the examples easily.
    """
    def __init__(self, egs_file, output_file=None):
        """Initialize a ChainExample object

        Given a egs_file, currently we support only scp files, we load
        the keys and pointers in the ark file into a dictionary, so that
        we don't have to load the entire egs file in memory

        Args:
            egs_file: scp file containing entries of egs
            output_file: this argument is used when each egs may belong to different languages
        """
        if output_file and egs_file.startswith('scp:'):
            raise ValueError("need egs_file to start to be of type scp when using output_file")
        self.egs_file = egs_file
#       TODO: error handling
        egs_list = [ln.strip().split() for ln in open(egs_file)]
        self.egs_dict = OrderedDict(egs_list)
        self.egs_keys = [x for x in self.egs_dict]
        if output_file:
            self.output_file = output_file
            self.lang_ids = dict([ln.strip().split() for ln in open(output_file)])
        else:
            self.output_file = None

    def __len__(self):
        return len(self.egs_dict)

    def __getitem__(self, idx):
        # key is the utterance id. it is likely to be a sub-utterance id
        key = self.egs_keys[idx]
        value = self.egs_dict[key]
        # if the output_file was passed, then language ids should exist
        if self.output_file:
            if key in self.lang_ids:
                lang_id = self.lang_ids[key]
            else:
                lang_id = -1
            return (key, value, lang_id)
        else:
            return (key, value, lang_id)
        
def load_egs(egs_file):
    """Loads the contents of the egs file.

    Given an egs file created for chain model training, load the
    contents of the and return as an array of NnetChainExample

    Args:
        egs_file: scp or ark file, should be prefix accordingly just like Kaldi
    
    Returns:
        A list of NnetChainExample
    """
    return kaldi.chain.ReadChainEgsFile(egs_file, 0)

def prepare_minibatch(egs_file, minibatch_size):
    """Prepare an array of minibatches from an egs file

    It loads the contents of the egs_file in memory, shuffles them
    and returns an array of minibatches.

    Args:
        egs_file: scp or ark file (a string), should be prefix accordingly just like Kaldi
        minibatch_size: a string of minibatch sizes separated by commas. E.g "64" or "128,64"
    
    Returns:
        A list of NnetChainExample. Each item contains merged examples with number of 
        sequences as given in the minibatch_size
    """
    egs = load_egs(egs_file)
    random.shuffle(egs)
    merged_egs = kaldi.chain.MergeChainEgs(egs, str(minibatch_size))
    return merged_egs

def train_lfmmi_one_iter(model, egs_file, den_fst_path, training_opts, feat_dim, 
                         minibatch_size="64", use_gpu=True, lr=0.0001, 
                         weight_decay=0.25, frame_shift=0, 
                         start_index=1, chunk_length=165,
                         print_interval=10):
    """Run one iteration of LF-MMI training

    The function loads the latest model, takes a list of egs, path to denominator
    fst and runs through the merged egs for one iteration of training. This is 
    similar to how one iteration of training is completed in Kaldi.

    Args:
        model: Path to pytorch model (.pt file)
        egs_file: scp or ark file (a string), should be prefix accordingly just like Kaldi
        den_fst_path: path to den.fst file
        training_opts: options of type ChainTrainingOpts
        feat_dim: dimension of features (e.g. 40 for MFCC hires features)
        minibatch_size: a string of minibatch sizes separated by commas. E.g "64" or "128,64"
        use_gpu: a boolean to set or unset the use of GPUs while training
        lr: learning rate
        frame_shift: an integer (usually 0, 1, or 2) used to shift the training features
        start_index: offset to training features. default value is 1. this is necessary because
            we do not know the context required by the model at this point
        chunk_length: length of the sequence. Note, this will not be required in the future
            as we will directly infer the length from the egs
        print_interval: the interval (a positive integer) to print the loss value

    Returns:
        updated model in CPU
    """
    # this is required to make sure Kaldi uses GPU
    pkwrap.kaldi.InstantiateKaldiCuda()
    # we need some default values for computing the MMI cost function. If is
    # not provided, create it    
    if training_opts is None:
        training_opts = pkwrap.kaldi.chain.CreateChainTrainingOptionsDefault()
    # load the graph
    den_graph = pkwrap.kaldi.chain.LoadDenominatorGraph(den_fst_path, model.output_dim)
    # use MMI criterion
    criterion = pkwrap.chain.KaldiChainObjfFunction.apply
    if use_gpu:
        model = model.cuda()
    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)
    acc_sum = torch.tensor(0., requires_grad=False)
    start_index = start_index+frame_shift
    end_index = start_index+frame_shift+chunk_length
    for mb_id, merged_egs in enumerate(pkwrap.chain.prepare_minibatch(egs_file, minibatch_size, 0)):
        features = pkwrap.kaldi.chain.GetFeaturesFromEgs(merged_egs)
        features = features[:,start_index:end_index,:]
        features = features.cuda()
        output, xent_output = model(features)
        sup = pkwrap.kaldi.chain.GetSupervisionFromEgs(merged_egs)
        deriv = criterion(training_opts, den_graph, sup, output, xent_output)
        acc_sum.add_(deriv[0])
        if mb_id>0 and mb_id%print_interval==0:
            sys.stderr.write("Overall objf={}\n".format(acc_sum/print_interval))
            acc_sum.zero_()
        optimizer.zero_grad()
        deriv.backward()
        clip_grad_value_(model.parameters(), 5.0)
        optimizer.step()
    sys.stdout.flush()
    model = model.cpu()
    return model
